{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e9e56d-d2cb-40ae-b872-4428fe8f3142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import warnings\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Twitter_Sentiments.csv')\n",
    "\n",
    "# Define functions for text preprocessing\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for word in r:\n",
    "        input_txt = re.sub(word, \"\", input_txt)\n",
    "    return input_txt\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['Cleaned_Tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\")\n",
    "df['Cleaned_Tweet'] = df['Cleaned_Tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "df['Cleaned_Tweet'] = df['Cleaned_Tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w) > 3]))\n",
    "df['Cleaned_Tweet'] = df['Cleaned_Tweet'].apply(remove_emojis)\n",
    "df['Cleaned_Tweet'] = df['Cleaned_Tweet'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
    "df['Cleaned_Tweet'] = df['Cleaned_Tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w) > 3]))\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = df['Cleaned_Tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = \" \".join(tokenized_tweet[i])\n",
    "df['Cleaned_Tweet'] = tokenized_tweet\n",
    "\n",
    "# Feature extraction\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "bow = bow_vectorizer.fit_transform(df['Cleaned_Tweet'])\n",
    "\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(bow, df['label'], random_state=42, test_size=0.25)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "xgb_model.get_booster().save_model('xgb_model.json')\n",
    "joblib.dump(bow_vectorizer, 'bow_vectorizer.joblib')\n",
    "\n",
    "# Evaluate the model\n",
    "pred = xgb_model.predict(x_test)\n",
    "f1 = f1_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "# Save the vectorizer\n",
    "\n",
    "\n",
    "# Function to preprocess new reviewIt's waste of money\n",
    "def preprocess_review(review):\n",
    "    review = remove_pattern(review, \"@[\\w]*\")\n",
    "    review = re.sub(\"[^a-zA-Z#]\", \" \", review)\n",
    "    review = remove_emojis(review)\n",
    "    review = review.encode('ascii', 'ignore').decode('ascii')\n",
    "    review = \" \".join([w for w in review.split() if len(w) > 3])\n",
    "    review = \" \".join([stemmer.stem(w) for w in review.split()])\n",
    "    return review\n",
    "\n",
    "# Function to predict sentiment of a new review\n",
    "def predict_sentiment(review):\n",
    "    processed_review = preprocess_review(review)\n",
    "    review_bow = bow_vectorizer.transform([processed_review])\n",
    "    prediction = xgb_model.predict(review_bow)\n",
    "    return 'positive' if prediction == 0 else 'negative'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3308ef2-8172-4c96-a338-53c7805ff696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(\n",
    "    xgb_model,open('regmodel.pkl','wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d655b35-cecf-4b9c-bf36-613d2005746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model=pickle.load(open('regmodel.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6394da-898e-4ed2-b10e-6e5e78deb7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064b8ba-2012-4d6a-9f98-1c53eae3fecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530c609-6cdd-4a08-92d2-ba15ff02d088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe769b7-739f-4669-9eb2-81d4429f73aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9997c77-fcc1-4f7e-92ef-49f822d468be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
